

######The dataset have following columns claim_id,member_id,provider_id,diagnosis_code,procedure_code,claim_amount,billed_amount,provider_type,days_in_hospital,prior_claims,claim_status,age,gender,plan_type,network_status,service_type,authorization_required,authorization_obtained,now we want to normalise/scale numerical variables and encode categorical variables (label encoder or one hot)


import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split

# Load your dataset
# df = pd.read_csv('your_data.csv')  # Assuming it's loaded already

# Step 1: Identify column types
numerical_cols = ['claim_amount', 'billed_amount', 'days_in_hospital', 'prior_claims', 'age']
categorical_cols = [
    'diagnosis_code', 'procedure_code', 'provider_type', 'claim_status', 
    'gender', 'plan_type', 'network_status', 'service_type',
    'authorization_required', 'authorization_obtained'
]

# Step 2: Handle IDs - drop or retain based on use case
id_cols = ['claim_id', 'member_id', 'provider_id']
# You can optionally drop them if not needed:
df_model = df.drop(columns=id_cols)

# Step 3: Define transformers
# One-hot encode categorical columns (you can change to LabelEncoder for low cardinality)
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ]
)

# Step 4: Apply transformations
# You can also wrap in a Pipeline with a model if needed
X = df_model.drop(columns=['claim_status'])  # example: assuming claim_status is the target
y = df_model['claim_status']

X_processed = preprocessor.fit_transform(X)

print("Shape after preprocessing:", X_processed.shape)



label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)




######build a binary classification model to predict whether a claim will be approved or denied based on available claim data


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Load your data (assuming df is already available)
# df = pd.read_csv("claims.csv")

# Step 1: Define columns
numerical_cols = ['claim_amount', 'billed_amount', 'days_in_hospital', 'prior_claims', 'age']
categorical_cols = [
    'diagnosis_code', 'procedure_code', 'provider_type',
    'gender', 'plan_type', 'network_status', 'service_type',
    'authorization_required', 'authorization_obtained'
]

# Step 2: Prepare data
df = df.copy()
df = df.drop(columns=['claim_id', 'member_id', 'provider_id'])  # Drop ID columns

# Label encode target if it's string
if df['claim_status'].dtype == 'object':
    label_encoder = LabelEncoder()
    df['claim_status'] = label_encoder.fit_transform(df['claim_status'])

# Step 3: Feature-target split
X = df.drop(columns='claim_status')
y = df['claim_status']

# Step 4: Preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ]
)

# Step 5: Combine with model in a pipeline
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

# Step 6: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 7: Fit the model
pipeline.fit(X_train, y_train)

# Step 8: Predict and evaluate
y_pred = pipeline.predict(X_test)

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))




######In a dataset we have a column name diagnosis_code like J20.7 now I want to extract the code prefixes so can you please code in python for this


import pandas as pd

# Sample DataFrame
df = pd.DataFrame({
    'diagnosis_code': ['J20.7', 'A15.0', 'B99', 'E11.9', 'K35.80']
})

# Extract prefix (letters followed by digits before decimal)
df['diagnosis_prefix'] = df['diagnosis_code'].str.extract(r'^([A-Z]+\d+)')

print(df)




#######flag for unusually high claim-to-bill ration

import pandas as pd
import numpy as np

# Example DataFrame
# df = pd.read_csv("your_data.csv")  # Assuming it's already loaded

# Step 1: Compute claim-to-bill ratio
df['claim_to_bill_ratio'] = df['claim_amount'] / df['billed_amount']

# Step 2: Handle divide-by-zero or NaNs
df['claim_to_bill_ratio'].replace([np.inf, -np.inf], np.nan, inplace=True)
df['claim_to_bill_ratio'].fillna(0, inplace=True)

# Step 3: Define a threshold (e.g., flag anything above 95th percentile)
threshold = df['claim_to_bill_ratio'].quantile(0.95)

# Step 4: Flag high ratios
df['high_claim_to_bill_ratio'] = df['claim_to_bill_ratio'] > threshold

# Optional: Print flagged rows
flagged = df[df['high_claim_to_bill_ratio']]
print("Flagged rows:\n", flagged[['claim_amount', 'billed_amount', 'claim_to_bill_ratio']])


#######group provider_type into higher-level categories


import pandas as pd

# Example DataFrame
df = pd.DataFrame({
    'provider_type': [
        'Physician', 'Clinic', 'Specialist', 'Outpatient', 'Hospital',
        'Nurse Practitioner', 'Pharmacy', 'Lab', 'Imaging Center', 'Dentist'
    ]
})

# Step 1: Define mapping to higher-level categories
provider_group_map = {
    'Physician': 'Individual',
    'Specialist': 'Individual',
    'Nurse Practitioner': 'Individual',
    'Dentist': 'Individual',
    
    'Clinic': 'Facility',
    'Outpatient': 'Facility',
    'Hospital': 'Facility',
    'Imaging Center': 'Facility',
    'Lab': 'Facility',

    'Pharmacy': 'Pharmacy',
    # Add more custom categories if needed
}

# Step 2: Apply the mapping
df['provider_group'] = df['provider_type'].map(provider_group_map).fillna('Other')

print(df)




####now do model building :1) binary classification: Approved(0) vs Denied(1), 2) train-test split(stratified),  3) train models: 1) Logistic Regression 2)Xgboost

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix

# If not already done: define features
numerical_cols = ['claim_amount', 'billed_amount', 'days_in_hospital', 'prior_claims', 'age']
categorical_cols = [
    'diagnosis_code', 'procedure_code', 'provider_type', 'gender', 
    'plan_type', 'network_status', 'service_type', 
    'authorization_required', 'authorization_obtained'
]

# Drop IDs if present
df = df.drop(columns=['claim_id', 'member_id', 'provider_id'], errors='ignore')

# Ensure target is binary (0 = Approved, 1 = Denied)
if df['claim_status'].dtype == 'object':
    df['claim_status'] = df['claim_status'].map({'Approved': 0, 'Denied': 1})




X = df.drop(columns='claim_status')
y = df['claim_status']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)



preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
])


logreg_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

logreg_pipeline.fit(X_train, y_train)
y_pred_logreg = logreg_pipeline.predict(X_test)

print("🔹 Logistic Regression Results:")
print(confusion_matrix(y_test, y_pred_logreg))
print(classification_report(y_test, y_pred_logreg))




xgb_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))
])

xgb_pipeline.fit(X_train, y_train)
y_pred_xgb = xgb_pipeline.predict(X_test)

print("🔹 XGBoost Results:")
print(confusion_matrix(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb))


##########now do model evaluation:1) Metrics(confusion matrix,ROC-AUC,precision,Recall,F1-score(especially important in imbalance) 2) Handle imbalance using (class weights,SMOTE)


from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score, roc_curve
)
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import matplotlib.pyplot as plt
import seaborn as sns


def evaluate_model(y_true, y_pred, y_proba):
    print("Confusion Matrix:")
    print(confusion_matrix(y_true, y_pred))
    print("\nClassification Report:")
    print(classification_report(y_true, y_pred))

    roc_auc = roc_auc_score(y_true, y_proba)
    print(f"ROC AUC Score: {roc_auc:.4f}")

    # Plot ROC Curve
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    plt.figure(figsize=(6, 4))
    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend()
    plt.grid()
    plt.tight_layout()
    plt.show()



logreg_weighted_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))
])

logreg_weighted_pipeline.fit(X_train, y_train)
y_pred_lr = logreg_weighted_pipeline.predict(X_test)
y_proba_lr = logreg_weighted_pipeline.predict_proba(X_test)[:, 1]

print("🔹 Logistic Regression with Class Weights")
evaluate_model(y_test, y_pred_lr, y_proba_lr)



# Estimate imbalance ratio
imbalance_ratio = y_train.value_counts()[0] / y_train.value_counts()[1]

xgb_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', XGBClassifier(scale_pos_weight=imbalance_ratio, use_label_encoder=False,
                                 eval_metric='logloss', random_state=42))
])

xgb_pipeline.fit(X_train, y_train)
y_pred_xgb = xgb_pipeline.predict(X_test)
y_proba_xgb = xgb_pipeline.predict_proba(X_test)[:, 1]

print("🔹 XGBoost with scale_pos_weight")
evaluate_model(y_test, y_pred_xgb, y_proba_xgb)



smote = SMOTE(random_state=42)

smote_logreg_pipeline = ImbPipeline([
    ('preprocessor', preprocessor),
    ('smote', smote),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

smote_logreg_pipeline.fit(X_train, y_train)
y_pred_sm = smote_logreg_pipeline.predict(X_test)
y_proba_sm = smote_logreg_pipeline.predict_proba(X_test)[:, 1]

print("🔹 Logistic Regression with SMOTE")
evaluate_model(y_test, y_pred_sm, y_proba_sm)



#####Explainability 1)Use SHAP or feature importance to explain predictions 2) highlight top reasons for likely denial

import shap

# Train model on the full dataset (optional if already trained)
model = xgb_pipeline.named_steps['classifier']
X_transformed = preprocessor.fit_transform(X_train)

# Use TreeExplainer for XGBoost
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_transformed)

# Get feature names after one-hot encoding
ohe = preprocessor.named_transformers_['cat']
feature_names = numerical_cols + list(ohe.get_feature_names_out(categorical_cols))

# Convert to SHAP summary format
shap.summary_plot(shap_values, X_transformed, feature_names=feature_names, plot_type="bar")



# Pick a sample claim
sample_index = 10
X_sample = X_test.iloc[[sample_index]]
X_sample_transformed = preprocessor.transform(X_sample)

# Compute SHAP values for the sample
shap_sample = explainer.shap_values(X_sample_transformed)

# Plot force plot to explain the decision
shap.initjs()
shap.force_plot(
    explainer.expected_value,
    shap_sample,
    features=X_sample_transformed,
    feature_names=feature_names
)




import matplotlib.pyplot as plt
import numpy as np

importances = model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10, 6))
plt.title("XGBoost Feature Importances")
plt.bar(range(20), importances[indices[:20]])
plt.xticks(range(20), [feature_names[i] for i in indices[:20]], rotation=90)
plt.tight_layout()
plt.show()




#####identify high risk claims and denial patterns

# Get predicted probabilities
X_all_transformed = preprocessor.transform(X)
denial_probs = xgb_pipeline.named_steps['classifier'].predict_proba(X_all_transformed)[:, 1]

# Add to original DataFrame
df['denial_probability'] = denial_probs

# Define a threshold (e.g., 80%+ chance of denial)
high_risk_claims = df[df['denial_probability'] > 0.80]

print("Top high-risk claims:\n", high_risk_claims.head())



shap.summary_plot(shap_values, X_transformed, feature_names=feature_names, plot_type="bar")








import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE

# Load your dataset
df = pd.read_csv("your_claims_data.csv")  # Replace with your actual file path

# Prepare features and target
X = df.drop(['target', 'claim_id', 'member_id', 'provider_id'], axis=1)
y = df['target']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Apply SMOTE to training data
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# -------------------------
# Logistic Regression
# -------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_smote)
X_test_scaled = scaler.transform(X_test)

# Train Logistic Regression with class_weight='balanced'
logreg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)
logreg.fit(X_train_scaled, y_train_smote)
y_pred_logreg = logreg.predict(X_test_scaled)

print("Logistic Regression Report (SMOTE + balanced):")
print(classification_report(y_test, y_pred_logreg))

# -------------------------
# XGBoost
# -------------------------

# Recalculate scale_pos_weight using original (imbalanced) y_train
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

# Train XGBoost with SMOTE data and scale_pos_weight
xgb = XGBClassifier(
    scale_pos_weight=scale_pos_weight,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)
xgb.fit(X_train_smote, y_train_smote)
y_pred_xgb = xgb.predict(X_test)

print("XGBoost Report (SMOTE + scale_pos_weight):")
print(classification_report(y_test, y_pred_xgb))





from sklearn.cluster import KMeans

# Use only denied claims
denied_claims = df[df['claim_status'] == 1].copy()
X_denied = preprocessor.transform(denied_claims[categorical_cols + numerical_cols])

# Cluster into patterns
kmeans = KMeans(n_clusters=3, random_state=42)
denied_claims['cluster'] = kmeans.fit_predict(X_denied)

# Analyze clusters
for c in denied_claims['cluster'].unique():
    print(f"\n--- Cluster {c} Summary ---")
    print(denied_claims[denied_claims['cluster'] == c].describe(include='all'))



# Check denial rates by provider_type
print(df.groupby('provider_type')['claim_status'].mean().sort_values(ascending=False))

# Denial rate by diagnosis or procedure code
print(df.groupby('diagnosis_code')['claim_status'].mean().sort_values(ascending=False).head(10))

















import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# ✅ Step 1: Encode target if needed
if df['claim_status'].dtype == 'object':
    le = LabelEncoder()
    df['claim_status'] = le.fit_transform(df['claim_status'])

# ✅ Step 2: Feature-target split
X = df.drop(columns='claim_status')
y = df['claim_status']

# ✅ Step 3: Drop ID columns
X = X.drop(columns=['claim_id', 'member_id', 'provider_id'], errors='ignore')

# ✅ Step 4: Define column types
numerical_cols = ['claim_amount', 'billed_amount', 'days_in_hospital', 'prior_claims', 'age']
categorical_cols = [
    'diagnosis_code', 'procedure_code', 'provider_type',
    'gender', 'plan_type', 'network_status', 'service_type',
    'authorization_required', 'authorization_obtained'
]

# ✅ Step 5: Separate numericals and categoricals
X_num = X[numerical_cols].copy()
X_cat = X[categorical_cols].copy()

# ✅ Step 6: Scale numerical features
scaler = StandardScaler()
X_num_scaled = scaler.fit_transform(X_num)

# ✅ Step 7: Encode categorical features
encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
X_cat_encoded = encoder.fit_transform(X_cat)

# ✅ Step 8: Combine processed features
X_processed = np.hstack([X_num_scaled, X_cat_encoded])

# ✅ Step 9: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y, test_size=0.2, random_state=42, stratify=y
)

# ✅ Step 10: Train classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# ✅ Step 11: Predict and evaluate
y_pred = model.predict(X_test)

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))













import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE

# Load your dataset
df = pd.read_csv("your_claims_data.csv")  # Replace with your actual file

# Prepare features and target
X = df.drop(['target', 'claim_id', 'member_id', 'provider_id'], axis=1)
y = df['target']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# -------------------------
# Logistic Regression: Use SMOTE
# -------------------------
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_smote)
X_test_scaled = scaler.transform(X_test)

logreg = LogisticRegression(max_iter=1000, random_state=42)
logreg.fit(X_train_scaled, y_train_smote)
y_pred_logreg = logreg.predict(X_test_scaled)

print("Logistic Regression Report (using SMOTE only):")
print(classification_report(y_test, y_pred_logreg))

# -------------------------
# XGBoost: Use scale_pos_weight, no SMOTE
# -------------------------
# Calculate class imbalance ratio from original data
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

xgb = XGBClassifier(
    scale_pos_weight=scale_pos_weight,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)

print("XGBoost Report (using scale_pos_weight only):")
print(classification_report(y_test, y_pred_xgb))









import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE
import shap
import matplotlib.pyplot as plt

# Load data
df = pd.read_csv("your_claims_data.csv")  # Replace with your path

# Prepare features and target
X = df.drop(['target', 'claim_id', 'member_id', 'provider_id'], axis=1)
y = df['target']
feature_names = X.columns

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# ==========================
# Logistic Regression
# ==========================
# Use SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_smote)
X_test_scaled = scaler.transform(X_test)

logreg = LogisticRegression(max_iter=1000, random_state=42)
logreg.fit(X_train_scaled, y_train_smote)
y_pred_logreg = logreg.predict(X_test_scaled)

print("Logistic Regression Report:")
print(classification_report(y_test, y_pred_logreg))

# Feature importance for Logistic Regression
importance_logreg = np.abs(logreg.coef_[0])
top_idx = np.argsort(importance_logreg)[::-1]
print("\nTop features for claim denial (Logistic Regression):")
for i in top_idx[:10]:
    print(f"{feature_names[i]}: coef={logreg.coef_[0][i]:.4f}")

# ==========================
# XGBoost
# ==========================
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
xgb = XGBClassifier(scale_pos_weight=scale_pos_weight, use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)

print("\nXGBoost Report:")
print(classification_report(y_test, y_pred_xgb))

# Feature importance
xgb_importances = xgb.feature_importances_
top_idx_xgb = np.argsort(xgb_importances)[::-1]
print("\nTop features for claim denial (XGBoost):")
for i in top_idx_xgb[:10]:
    print(f"{feature_names[i]}: importance={xgb_importances[i]:.4f}")

# ==========================
# SHAP for XGBoost
# ==========================
explainer = shap.TreeExplainer(xgb)
shap_values = explainer.shap_values(X_test)

# Global explanation
print("\nSHAP Summary Plot (Global feature impact):")
shap.summary_plot(shap_values, X_test, feature_names=feature_names)

# Individual explanation (example: first denied claim in test set)
denied_index = y_test[y_test == 1].index[0]
print(f"\nExplanation for claim ID at test index {denied_index}:")
shap.force_plot(explainer.expected_value, shap_values[0], X_test.iloc[0], matplotlib=True)










import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import classification_report, confusion_matrix
import shap

# 🟩 Step 1: Label encode target: Approved=0, Denied=1
df['claim_status'] = df['claim_status'].map({'Approved': 0, 'Denied': 1})

# 🟩 Step 2: Define features and target
X = df.drop(columns=['claim_status', 'claim_id', 'member_id', 'provider_id'], errors='ignore')
y = df['claim_status']

# 🟩 Step 3: Column definitions
numerical_cols = ['claim_amount', 'billed_amount', 'days_in_hospital', 'prior_claims', 'age']
categorical_cols = [
    'diagnosis_code', 'procedure_code', 'provider_type',
    'gender', 'plan_type', 'network_status', 'service_type',
    'authorization_required', 'authorization_obtained'
]

# 🟩 Step 4: Manual preprocessing
# --- Scale numeric
scaler = StandardScaler()
X_num = scaler.fit_transform(X[numerical_cols])

# --- One-hot encode categorical
encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
X_cat = encoder.fit_transform(X[categorical_cols])

# --- Combine
X_processed = np.hstack([X_num, X_cat])

# Optional: feature names for SHAP
feature_names = numerical_cols + list(encoder.get_feature_names_out(categorical_cols))

# 🟩 Step 5: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y, test_size=0.2, stratify=y, random_state=42
)

# 🟩 Step 6: Train XGBoost model
model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
model.fit(X_train, y_train)

# 🟩 Step 7: Evaluate model
y_pred = model.predict(X_test)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# 🟩 Step 8: Predict probabilities for all claims
X_all_num = scaler.transform(X[numerical_cols])
X_all_cat = encoder.transform(X[categorical_cols])
X_all_transformed = np.hstack([X_all_num, X_all_cat])

denial_probs = model.predict_proba(X_all_transformed)[:, 1]
df['denial_probability'] = denial_probs

# 🟩 Step 9: Identify high-risk claims
high_risk_claims = df[df['denial_probability'] > 0.80]
print("Top high-risk claims:\n", high_risk_claims.head())

# 🟩 Step 10: SHAP for explainability
explainer = shap.Explainer(model, X_all_transformed, feature_names=feature_names)
shap_values = explainer(X_all_transformed)

# Bar plot of most important denial features
shap.summary_plot(shap_values, features=X_all_transformed, feature_names=feature_names, plot_type="bar")














from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear', 'saga'],
    'class_weight': [None, 'balanced']
}

logreg = LogisticRegression(max_iter=1000, random_state=42)
grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='f1', n_jobs=-1)
grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)












from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV

# Define model
xgb = XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=42)

# Estimate imbalance ratio (important for `scale_pos_weight`)
imbalance_ratio = (y_train == 0).sum() / (y_train == 1).sum()

# Define parameter grid
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.05, 0.1],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0],
    'scale_pos_weight': [1, imbalance_ratio]
}

# Grid search
grid_search = GridSearchCV(xgb, param_grid, cv=3, scoring='f1', verbose=1, n_jobs=-1)
grid_search.fit(X_train, y_train)

print("Best parameters for XGBoost:", grid_search.best_params_)





# 📊 Executive Summary: Claims Data Insights

## ✅ Data Quality
- No missing values detected.
- No duplicate records found.
- Dataset is clean and ready for modeling.

---

## 📈 Feature Relationships & Distributions
- `claim_amount` and `billed_amount` are **highly correlated**.
  - 📌 Recommendation: Use one or derive a **claim-to-bill ratio**.
- `days_in_hospital` is typically short:
  - Most patients stay **1–2 days**, indicating low-complexity procedures.

---

## 🩺 Claim Outcomes
- Majority of claims are **Approved**.
  - ⚠️ Indicates **class imbalance** in the target (`claim_status`).
  - 🔧 Requires:
    - Class weight adjustments
    - Oversampling (e.g., SMOTE)
    - Evaluation via ROC-AUC, F1-score

---

## 🌐 Network Participation
- Most claims are **In-Network**.
  - May limit variability for `network_status`.
  - Important to analyze the smaller **Out-of-Network** subset for higher denial risk.

---

## 🔐 Authorization Insights
- Most patients **require authorization**, and it is usually **obtained**.
- Denials often linked to:
  - Required but **missing authorization**
  - **Mismatch** between required vs. obtained fields

---

## 📌 Modeling Implications
- Drop one of `claim_amount` or `billed_amount`, or use their ratio.
- Address **class imbalance** with appropriate strategies.
- Focus on engineered features:
  - Claim-to-bill ratio
  - Authorization mismatch
  - Network status
  - Provider type

---

## 🚀 Recommendation
Use these insights to:
- Enhance model interpretability and performance.
- Focus on features linked to high denial risk.
- Build robust logic for **flagging high-risk claims**.






Sure! Let's **compare the performance** of your **Logistic Regression** model (from the image) with the **XGBoost** model you trained.

---

### 🧠 **Logistic Regression Model Performance (from image)**

From the confusion matrix:

|                         | Predicted Approved (0) | Predicted Denied (1)  |
| ----------------------- | ---------------------- | --------------------- |
| **Actual Approved (0)** | 7150 (True Negative)   | 1992 (False Positive) |
| **Actual Denied (1)**   | 164 (False Negative)   | 694 (True Positive)   |

**Classification Metrics:**

* **Accuracy**: `0.7844`
* **Precision**: `0.258`
* **Recall (Sensitivity)**: `0.808`
* **ROC AUC**: `0.795`

🧾 **Insights:**

* **High recall**: The model catches most denials.
* **Low precision**: Many false positives — approved claims predicted as denied.
* Suitable when it's more important to catch denials, even at the cost of false alarms.

---

### ⚙️ **XGBoost Model Performance (fill in below)**

Please provide the **confusion matrix and metrics for your XGBoost model** (or paste the classification report).

However, a typical well-tuned XGBoost model would yield:

| Metric    | Expected XGBoost Value                        |
| --------- | --------------------------------------------- |
| Accuracy  | \~0.82–0.88                                   |
| Precision | Higher than logistic (\~0.35–0.50)            |
| Recall    | Slightly lower or similar (e.g., \~0.75–0.85) |
| ROC AUC   | \~0.85–0.90                                   |

---

### 📊 **Comparison Summary**

| Metric    | Logistic Regression | XGBoost (Expected/Your Actual) |
| --------- | ------------------- | ------------------------------ |
| Accuracy  | 0.784               | ⬆️ Higher                      |
| Precision | 0.258               | ⬆️ Significantly Higher        |
| Recall    | 0.808               | ↔️ Similar or Slightly Lower   |
| ROC AUC   | 0.795               | ⬆️ Higher                      |

---

### ✅ **When to Prefer Which?**

| Use Case                                              | Recommended Model                    |
| ----------------------------------------------------- | ------------------------------------ |
| **Want to avoid missing denied claims (high recall)** | Logistic Regression or tuned XGBoost |
| **Want more reliable denial predictions (precision)** | XGBoost                              |
| **Overall performance and robustness**                | XGBoost                              |

---

If you share the XGBoost confusion matrix or report, I can update this with exact values and deeper insights.


